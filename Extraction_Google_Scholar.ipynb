{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "\n",
    "# Set up fake user agent\n",
    "ua = UserAgent()\n",
    "headers = {\"User-Agent\": ua.random}\n",
    "data1 = {\"Date Cited\": [],\"Paper Title\": [], \"Abstract\": []}\n",
    "\n",
    "# URL\n",
    "url = \"https://scholar.google.com/citations?hl=en&user=trMsrB4AAAAJ&view_op=list_works&sortby=pubdate\"\n",
    "\n",
    "# Send an HTTP GET request to the page\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    while True:\n",
    "        # Parse the HTML content of the page using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Find the container that holds the papers\n",
    "        papers_container = soup.find(\"tbody\", {\"id\": \"gsc_a_b\"})\n",
    "\n",
    "        if papers_container:\n",
    "            # Find all individual papers\n",
    "            papers = papers_container.find_all(\"tr\", {\"class\": \"gsc_a_tr\"})\n",
    "\n",
    "            # Iterate through each paper and extract information\n",
    "            for paper in papers:\n",
    "                # Extract title, date_cited, and href link\n",
    "                title_link = paper.find(\"a\", {\"class\": \"gsc_a_at\"})\n",
    "                title = title_link.text.strip()\n",
    "                date_cited = paper.find(\"td\", {\"class\": \"gsc_a_y\"}).text.strip()\n",
    "                # venue = paper.find(\"div\",{\"class\": \"gsc_oci_value\"}).text.strip()\n",
    "\n",
    "                data1[\"Paper Title\"].append(title)\n",
    "                data1[\"Date Cited\"].append(date_cited)\n",
    "                # data1[\"Venue\"].append(venue)\n",
    "\n",
    "                href_link = title_link[\"href\"]\n",
    "                paper_url = f\"https://scholar.google.com{href_link}\"\n",
    "\n",
    "                # Fetch the paper's page to extract the abstract\n",
    "                paper_response = requests.get(paper_url, headers=headers)\n",
    "                paper_soup = BeautifulSoup(paper_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the abstract if available\n",
    "                abstract_container = paper_soup.find(\"div\", {\"id\": \"gsc_oci_descr\", \"class\": \"gsc_oci_value\"})\n",
    "                if abstract_container:\n",
    "                    abstract = abstract_container.text.strip()\n",
    "                    data1[\"Abstract\"].append(abstract)\n",
    "                else:\n",
    "                    data1[\"Abstract\"].append(\"Abstract not available\")\n",
    "\n",
    "            # Check if there's a \"Show more\" button and it's not disabled\n",
    "            show_more_button = soup.find(\"button\", {\"id\": \"gsc_bpf_more\", \"disabled\": None})\n",
    "            if show_more_button:\n",
    "                # Click the \"Show more\" button to load additional papers\n",
    "                response = requests.get(url + \"&cstart=\" + str(len(data1[\"Paper Title\"])), headers=headers)\n",
    "            else:\n",
    "                # No more papers to load, exit the loop\n",
    "                break\n",
    "        else:\n",
    "            print(\"No papers found on the page.\")\n",
    "            break\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data1)\n",
    "\n",
    "    # Export the DataFrame to Excel\n",
    "    df.to_excel(\"papers_data.xlsx\", index=False)\n",
    "\n",
    "    print(\"Data extraction and export to Excel completed.\")\n",
    "else:\n",
    "    print(\"Failed to fetch the Google Scholar profile page.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
