{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f1517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4eab52c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Labiba Jahan\n",
      "Assistant Professor, Department of Computer Science\n",
      "\n",
      "Lyle School of Engineering\n",
      "\n",
      "Research:\n",
      "Natural Language Processing\n",
      "Narrative Understanding\n",
      "Machine Learning\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(\"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Mehak-Gupta\")\n",
    "\n",
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "\n",
    "res= soup.h4\n",
    "res1 = soup.h1\n",
    "\n",
    "print(res1.get_text())\n",
    "print(res.get_text())\n",
    "\n",
    "research_section = soup.find(\"div\", {\"class\": \"branding-links\"})\n",
    "if research_section:\n",
    "        # Extract the text from the \"Research\" section\n",
    "        research_text = research_section.get_text()\n",
    "print(research_text)\n",
    "\n",
    "research_elements = soup.find_all(\"li\", {\"class\": \"p1\"})\n",
    "print(\"Research:\")\n",
    "if research_elements:\n",
    "        # Loop through the found elements and print their text\n",
    "        for index, element in enumerate(research_elements):\n",
    "            print(element.get_text())\n",
    "else:\n",
    "    print(\"No elements with class 'research' found on the page.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77edf638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faculty Name: Dr. Labiba Jahan\n",
      "Email: ljahan@smu.edu\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Labiba-Jahan\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find and extract the desired information\n",
    "    faculty_name = soup.find(\"h1\").text\n",
    "    \n",
    "    # Find the <a> element with an href attribute containing \"mailto:\"\n",
    "    email_link = soup.find(\"a\", href=lambda href: href and \"mailto:\" in href)\n",
    "    \n",
    "    if email_link:\n",
    "        # Extract the email address from the href attribute\n",
    "        email = email_link[\"href\"].replace(\"mailto:\", \"\")\n",
    "        print(\"Faculty Name:\", faculty_name)\n",
    "        print(\"Email:\", email)\n",
    "    else:\n",
    "        print(\"Email not found on the page\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fd82175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1:\n",
      "  Faculty Name: Dr. Labiba Jahan\n",
      "  Machine Learning Mentions: 1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Labiba-Jahan\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find and extract the desired information\n",
    "    faculty_name = soup.find(\"h1\").text\n",
    "    \n",
    "    # Find all text on the page\n",
    "    page_text = soup.get_text()\n",
    "\n",
    "    # Search for occurrences of \"Machine Learning\" in the page text\n",
    "    machine_learning_mentions = page_text.count(\"Machine Learning\")\n",
    "\n",
    "    # Print the extracted data with custom formatting\n",
    "    print(\"L1:\")\n",
    "    print(\"  Faculty Name:\", faculty_name)\n",
    "    print(\"  Machine Learning Mentions:\", machine_learning_mentions)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d132c437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Labiba-Jahan\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the element containing the \"Research\" section\n",
    "    research_section = soup.find(\"li\", {\"class\": \"p1\"})\n",
    "\n",
    "    if research_section:\n",
    "        # Extract the text from the \"Research\" section\n",
    "        research_text = research_section.get_text()\n",
    "        print(research_text)\n",
    "    else:\n",
    "        print(\"Research section not found on the page.\")\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35520c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements with class 'research': 27\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Labiba-Jahan\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all elements with the class \"research\"\n",
    "    #research_elements = soup.find_all(class_=\"p1\")\n",
    "    research_section = soup.find(\"li\", {\"class\": \"p1\"})\n",
    "    \n",
    "    if research_section:\n",
    "        # Extract the text from the \"Research\" section\n",
    "        research_text = research_section.get_text()\n",
    "    #for element in research_text:\n",
    "        #print(element)\n",
    "    # Count the number of elements found\n",
    "    num_research_elements = len(research_text)\n",
    "     #print(f\"elements with class 'p1': {num_research_elements}\")\n",
    "    print(f\"Number of elements with class 'research': {num_research_elements}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8caadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Labiba-Jahan\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all elements with the class \"research\"\n",
    "    research_elements = soup.find_all(class_=\"research\")\n",
    "\n",
    "    # Print each element\n",
    "    for element in research_elements:\n",
    "        print(element)\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16885de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/David-Lin:\n",
      "Natural Language Processing\n",
      "Database Systems\n",
      "Data mining\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Theodore-Manikas:\n",
      "Computer Architecture\n",
      "Circuit Testing\n",
      "Optimization Methods\n",
      "Security\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Eric-Larson:\n",
      "Machine Learning and Deep Learning\n",
      "Privacy and Security\n",
      "Applied Machine Learning in Health and Education\n",
      "Human Machine Teaming and Biometrics\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Frank-Coyle-PhD:\n",
      "Machine Learning / Artificial Intelligence\n",
      "Software Engineering\n",
      "Large Language Models\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Mehak-Gupta:\n",
      "Deep Learning\n",
      "Supervised and Semi-supervised machine learning\n",
      "Structured and Unstructured medical data\n",
      "Predictive modeling\n",
      "Natural Language Processing\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Ginger-Alford:\n",
      "Visual and Spatial Computing\n",
      "Applications of Emerging Immersive 3D Technologies in Museums\n",
      "Animatronics Education (Embedding robotics in arts and humanities stories)\n",
      "Light Fields and Novel Displays\n",
      "Applications of Blue Noise in Machine Learning\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Jia-Zhang:\n",
      "Data Science Infrastructure\n",
      "\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "\n",
      "Scientific Workflow\n",
      "\n",
      "\n",
      "Software Engineering\n",
      "\n",
      "\n",
      "Cloud Computing\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Jeff-Tian:\n",
      "Software testing, especially usage-/risk-based testing\n",
      "\n",
      "Usability and user experience (UX) measurement and improvement\n",
      "\n",
      "Software measurement and empirical software engineering\n",
      "\n",
      "Software reliability and safety\n",
      "\n",
      "Cloud and service computing\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/K-Periyasamy:\n",
      "Software Engineering\n",
      "\n",
      "\n",
      "Formal Methods\n",
      "\n",
      "\n",
      "Data Science\n",
      "\n",
      "\n",
      "Healthcare Applications\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Klyne-Smith-PhD:\n",
      "Software Engineering Life Cycle Model Delivery Engagement\n",
      "Project Management Optimization and Risk Management\n",
      "Intersection and Dependencies of Software Engineering and Project Management\n",
      "Requirements and Software Engineering associated with Cybersecurity, Machine Learning, and Artificial Intelligence\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Labiba-Jahan:\n",
      "Natural Language Processing\n",
      "Narrative Understanding\n",
      "Machine Learning\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/LiGuo-Huang:\n",
      "AI and Software Engineering\n",
      "Software Data Analytics\n",
      "Software Quality\n",
      "Software Maintenance and Evolution\n",
      "Software and System Processes\n",
      "Empirical Software Engineering\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Maya-El-Dayeh:\n",
      "Cloud Computing\n",
      "Data Mining\n",
      "Software Engineering\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Michael-Hahsler:\n",
      "Artificial Intelligence\n",
      "Machine Learning\n",
      "Data Mining\n",
      "Data Science\n",
      "\n",
      "\n",
      "Found 'Research' on https://www.smu.edu/Lyle/Departments/CS/People/Faculty/Nurcan-Yuruk:\n",
      "Data Mining\n",
      "Social Network Analysis\n",
      "Applied Machine Learning\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Base URL of the page containing faculty names and links\n",
    "base_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Send an HTTP GET request to the page\n",
    "response = requests.get(base_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Extract faculty website links and store them in an array\n",
    "    faculty_links = []\n",
    "\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(base_url, faculty_link)\n",
    "            faculty_links.append(absolute_url)\n",
    "\n",
    "    # Print the faculty website links\n",
    "    #for link in faculty_links:\n",
    "        #print(link)\n",
    "\n",
    "    # Store faculty website links in an array\n",
    "    faculty_links_array = faculty_links\n",
    "\n",
    "    # Now, you have all faculty website links in the 'faculty_links_array' variable.\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")\n",
    "\n",
    "for url in faculty_links_array:\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Search for the \"Research\" heading\n",
    "        research_heading = soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "        if research_heading:\n",
    "            print(f\"Found 'Research' on {url}:\")\n",
    "            # Print the content that follows the \"Research\" heading\n",
    "            for sibling in research_heading.find_next_siblings():\n",
    "                # Stop when another heading or paragraph is encountered\n",
    "                if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                    break\n",
    "                if sibling.get_text().strip():\n",
    "                    print(sibling.get_text().strip())\n",
    "            print(\"\\n\")        \n",
    "        else:\n",
    "            print(f\"'Research' not found on {url}.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch {url}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b863f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the page containing the website URLs\n",
    "page_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"  # Replace with the actual URL\n",
    "\n",
    "# Send an HTTP GET request to the page\n",
    "response = requests.get(page_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all anchor (a) tags with href attributes\n",
    "    anchor_tags = soup.find_all(\"li\", href=True)\n",
    "\n",
    "    # Extract and print the website URLs\n",
    "    for anchor in anchor_tags:\n",
    "        url = anchor[\"href\"]\n",
    "        print(url)\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93bff44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faculty Name: David (King Ip) Lin, Ph.D.\n",
      "Research Areas are:\n",
      "Natural Language Processing\n",
      "Database Systems\n",
      "Data mining\n",
      "\n",
      "\n",
      "Faculty Name: Theodore Manikas, Ph.D.\n",
      "Research Areas are:\n",
      "Computer Architecture\n",
      "Circuit Testing\n",
      "Optimization Methods\n",
      "Security\n",
      "\n",
      "\n",
      "Faculty Name: Eric Larson, Ph.D.\n",
      "Research Areas are:\n",
      "Machine Learning and Deep Learning\n",
      "Privacy and Security\n",
      "Applied Machine Learning in Health and Education\n",
      "Human Machine Teaming and Biometrics\n",
      "\n",
      "\n",
      "Faculty Name: Frank Coyle, Ph.D.\n",
      "Research Areas are:\n",
      "Machine Learning / Artificial Intelligence\n",
      "Software Engineering\n",
      "Large Language Models\n",
      "\n",
      "\n",
      "Faculty Name: Mehak Gupta, Ph.D.\n",
      "Research Areas are:\n",
      "Deep Learning\n",
      "Supervised and Semi-supervised machine learning\n",
      "Structured and Unstructured medical data\n",
      "Predictive modeling\n",
      "Natural Language Processing\n",
      "\n",
      "\n",
      "Faculty Name: Ginger Alford, Ph.D.\n",
      "Research Areas are:\n",
      "Visual and Spatial Computing\n",
      "\n",
      "\n",
      "Applications of Emerging Immersive 3D Technologies in Museums\n",
      "\n",
      "\n",
      "Animatronics Education (Embedding robotics in arts and humanities stories)\n",
      "\n",
      "\n",
      "Light Fields and Novel Displays\n",
      "\n",
      "\n",
      "Applications of Blue Noise in Machine Learning\n",
      "\n",
      "\n",
      "Faculty Name: Jia Zhang, Ph.D.\n",
      "Research Areas are:\n",
      "Data Science Infrastructure\n",
      "\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "\n",
      "Scientific Workflow\n",
      "\n",
      "\n",
      "Software Engineering\n",
      "\n",
      "\n",
      "Cloud Computing\n",
      "\n",
      "\n",
      "Faculty Name: Jeff Tian, Ph.D.\n",
      "Research Areas are:\n",
      "Software testing, especially usage-/risk-based testing\n",
      "Usability and user experience (UX) measurement and improvement\n",
      "Software measurement and empirical software engineering\n",
      "Software reliability and safety\n",
      "Cloud and service computing\n",
      "\n",
      "\n",
      "Faculty Name: Kasilingam Periyasamy, Ph.D.\n",
      "Research Areas are:\n",
      "Software Engineering\n",
      "\n",
      "\n",
      "Formal Methods\n",
      "\n",
      "\n",
      "Data Science\n",
      "\n",
      "\n",
      "Healthcare Applications\n",
      "\n",
      "\n",
      "Faculty Name: Klyne Smith, Eng.D.\n",
      "Research Areas are:\n",
      "Software Engineering Life Cycle Model Delivery Engagement\n",
      "Project Management Optimization and Risk Management\n",
      "Intersection and Dependencies of Software Engineering and Project Management\n",
      "Requirements and Software Engineering associated with Cybersecurity, Machine Learning, and Artificial Intelligence\n",
      "\n",
      "\n",
      "Faculty Name: Labiba Jahan, Ph.D.\n",
      "Research Areas are:\n",
      "Natural Language Processing\n",
      "\n",
      "\n",
      "Narrative Understanding\n",
      "\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "\n",
      "Faculty Name: LiGuo Huang, Ph.D.\n",
      "Research Areas are:\n",
      "AI and Software Engineering\n",
      "Software Data Analytics\n",
      "Software Quality\n",
      "Software Maintenance and Evolution\n",
      "Software and System Processes\n",
      "Empirical Software Engineering\n",
      "\n",
      "\n",
      "Faculty Name: Maya El Dayeh, Ph.D.\n",
      "Research Areas are:\n",
      "Cloud Computing\n",
      "Data Mining\n",
      "Software Engineering\n",
      "\n",
      "\n",
      "Faculty Name: Michael Hahsler, Ph.D.\n",
      "Research Areas are:\n",
      "Artificial Intelligence\n",
      "Machine Learning\n",
      "Data Mining\n",
      "Data Science\n",
      "\n",
      "\n",
      "Faculty Name: Nurcan Yuruk, Ph.D.\n",
      "Research Areas are:\n",
      "Data Mining\n",
      "Social Network Analysis\n",
      "Applied Machine Learning\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract and print the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "                print(\"Faculty Name:\", faculty_name)\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    #print(f\"Found 'Research' on {absolute_url}:\")\n",
    "                    print(f\"Research Areas are:\")\n",
    "                    # Print the content that follows the \"Research\" heading\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        # Stop when another heading or paragraph is encountered\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        if sibling.get_text().strip():\n",
    "                            print(sibling.get_text().strip())\n",
    "                    print(\"\\n\")\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41065a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faculty Name: David (King Ip) Lin, Ph.D.\n",
      "Research Areas: ['Natural Language Processing\\nDatabase Systems\\nData mining']\n",
      "\n",
      "Faculty Name: Theodore Manikas, Ph.D.\n",
      "Research Areas: ['Computer Architecture\\nCircuit Testing\\nOptimization Methods\\nSecurity']\n",
      "\n",
      "Faculty Name: Eric Larson, Ph.D.\n",
      "Research Areas: ['Machine Learning and Deep Learning\\nPrivacy and Security\\nApplied Machine Learning in Health and Education\\nHuman Machine Teaming and Biometrics']\n",
      "\n",
      "Faculty Name: Frank Coyle, Ph.D.\n",
      "Research Areas: ['Machine Learning / Artificial Intelligence', 'Software Engineering', 'Large Language Models']\n",
      "\n",
      "Faculty Name: Mehak Gupta, Ph.D.\n",
      "Research Areas: ['Deep Learning', 'Supervised and Semi-supervised machine learning', 'Structured and Unstructured medical data', 'Predictive modeling', 'Natural Language Processing']\n",
      "\n",
      "Faculty Name: Ginger Alford, Ph.D.\n",
      "Research Areas: ['Visual and Spatial Computing\\n\\n\\nApplications of Emerging Immersive 3D Technologies in Museums\\n\\n\\nAnimatronics Education (Embedding robotics in arts and humanities stories)\\n\\n\\nLight Fields and Novel Displays\\n\\n\\nApplications of Blue Noise in Machine Learning']\n",
      "\n",
      "Faculty Name: Jia Zhang, Ph.D.\n",
      "Research Areas: ['Data Science Infrastructure\\n\\n\\nMachine Learning\\n\\n\\nScientific Workflow\\n\\n\\nSoftware Engineering\\n\\n\\nCloud Computing']\n",
      "\n",
      "Faculty Name: Jeff Tian, Ph.D.\n",
      "Research Areas: ['Software testing, especially usage-/risk-based testing', 'Usability and user experience (UX) measurement and improvement', 'Software measurement and empirical software engineering', 'Software reliability and safety', 'Cloud and service computing']\n",
      "\n",
      "Faculty Name: Kasilingam Periyasamy, Ph.D.\n",
      "Research Areas: ['Software Engineering\\n\\n\\nFormal Methods\\n\\n\\nData Science\\n\\n\\nHealthcare Applications']\n",
      "\n",
      "Faculty Name: Klyne Smith, Eng.D.\n",
      "Research Areas: ['Software Engineering Life Cycle Model Delivery Engagement', 'Project Management Optimization and Risk Management', 'Intersection and Dependencies of Software Engineering and Project Management', 'Requirements and Software Engineering associated with Cybersecurity, Machine Learning, and Artificial Intelligence']\n",
      "\n",
      "Faculty Name: Labiba Jahan, Ph.D.\n",
      "Research Areas: ['Natural Language Processing\\n\\n\\nNarrative Understanding\\n\\n\\nMachine Learning']\n",
      "\n",
      "Faculty Name: LiGuo Huang, Ph.D.\n",
      "Research Areas: ['AI and Software Engineering', 'Software Data Analytics', 'Software Quality', 'Software Maintenance and Evolution', 'Software and System Processes', 'Empirical Software Engineering']\n",
      "\n",
      "Faculty Name: Maya El Dayeh, Ph.D.\n",
      "Research Areas: ['Cloud Computing\\nData Mining\\nSoftware Engineering']\n",
      "\n",
      "Faculty Name: Michael Hahsler, Ph.D.\n",
      "Research Areas: ['Artificial Intelligence\\nMachine Learning\\nData Mining\\nData Science']\n",
      "\n",
      "Faculty Name: Nurcan Yuruk, Ph.D.\n",
      "Research Areas: ['Data Mining\\nSocial Network Analysis\\nApplied Machine Learning']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Initialize an empty list to store faculty data\n",
    "faculty_data_list = []\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    research_areas = []\n",
    "\n",
    "                    # Extract the research areas, removing extra newlines and leading/trailing spaces\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        # Stop when another heading or paragraph is encountered\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        text = sibling.get_text().strip()\n",
    "                        if text:\n",
    "                            research_areas.append(text)\n",
    "\n",
    "                    # Create a dictionary for the faculty member's data\n",
    "                    faculty_data = {\n",
    "                        \"name\": faculty_name,\n",
    "                        \"research_areas\": research_areas\n",
    "                    }\n",
    "\n",
    "                    # Append the dictionary to the list\n",
    "                    faculty_data_list.append(faculty_data)\n",
    "\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "# Now you have a list of dictionaries containing faculty data\n",
    "for faculty in faculty_data_list:\n",
    "    print(\"Faculty Name:\", faculty[\"name\"])\n",
    "    print(\"Research Areas:\", faculty[\"research_areas\"])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b96bf705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faculty Name: David (King Ip) Lin, Ph.D.\n",
      "Research Areas: ['Natural Language Processing Database Systems Data mining']\n",
      "\n",
      "Faculty Name: Theodore Manikas, Ph.D.\n",
      "Research Areas: ['Computer Architecture Circuit Testing Optimization Methods Security']\n",
      "\n",
      "Faculty Name: Eric Larson, Ph.D.\n",
      "Research Areas: ['Machine Learning and Deep Learning Privacy and Security Applied Machine Learning in Health and Education Human Machine Teaming and Biometrics']\n",
      "\n",
      "Faculty Name: Frank Coyle, Ph.D.\n",
      "Research Areas: ['Machine Learning / Artificial Intelligence', 'Software Engineering', 'Large Language Models']\n",
      "\n",
      "Faculty Name: Mehak Gupta, Ph.D.\n",
      "Research Areas: ['Deep Learning', 'Supervised and Semi-supervised machine learning', 'Structured and Unstructured medical data', 'Predictive modeling', 'Natural Language Processing']\n",
      "\n",
      "Faculty Name: Ginger Alford, Ph.D.\n",
      "Research Areas: ['Visual and Spatial Computing Applications of Emerging Immersive 3D Technologies in Museums Animatronics Education (Embedding robotics in arts and humanities stories) Light Fields and Novel Displays Applications of Blue Noise in Machine Learning']\n",
      "\n",
      "Faculty Name: Jia Zhang, Ph.D.\n",
      "Research Areas: ['Data Science Infrastructure Machine Learning Scientific Workflow Software Engineering Cloud Computing']\n",
      "\n",
      "Faculty Name: Jeff Tian, Ph.D.\n",
      "Research Areas: ['Software testing, especially usage-/risk-based testing', 'Usability and user experience (UX) measurement and improvement', 'Software measurement and empirical software engineering', 'Software reliability and safety', 'Cloud and service computing']\n",
      "\n",
      "Faculty Name: Kasilingam Periyasamy, Ph.D.\n",
      "Research Areas: ['Software Engineering Formal Methods Data Science Healthcare Applications']\n",
      "\n",
      "Faculty Name: Klyne Smith, Eng.D.\n",
      "Research Areas: ['Software Engineering Life Cycle Model Delivery Engagement', 'Project Management Optimization and Risk Management', 'Intersection and Dependencies of Software Engineering and Project Management', 'Requirements and Software Engineering associated with Cybersecurity, Machine Learning, and Artificial Intelligence']\n",
      "\n",
      "Faculty Name: Labiba Jahan, Ph.D.\n",
      "Research Areas: ['Natural Language Processing Narrative Understanding Machine Learning']\n",
      "\n",
      "Faculty Name: LiGuo Huang, Ph.D.\n",
      "Research Areas: ['AI and Software Engineering', 'Software Data Analytics', 'Software Quality', 'Software Maintenance and Evolution', 'Software and System Processes', 'Empirical Software Engineering']\n",
      "\n",
      "Faculty Name: Maya El Dayeh, Ph.D.\n",
      "Research Areas: ['Cloud Computing Data Mining Software Engineering']\n",
      "\n",
      "Faculty Name: Michael Hahsler, Ph.D.\n",
      "Research Areas: ['Artificial Intelligence Machine Learning Data Mining Data Science']\n",
      "\n",
      "Faculty Name: Nurcan Yuruk, Ph.D.\n",
      "Research Areas: ['Data Mining Social Network Analysis Applied Machine Learning']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Define a custom function to clean up research areas\n",
    "def clean_research_areas(areas):\n",
    "    cleaned_areas = []\n",
    "    for area in areas:\n",
    "        # Remove extra whitespace, newlines, and empty lines\n",
    "        cleaned_area = \" \".join(area.split())\n",
    "        if cleaned_area:\n",
    "            cleaned_areas.append(cleaned_area)\n",
    "    return cleaned_areas\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Initialize an empty list to store faculty data\n",
    "faculty_data_list = []\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    research_areas = []\n",
    "\n",
    "                    # Extract the research areas\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        # Stop when another heading or paragraph is encountered\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        text = sibling.get_text()\n",
    "                        research_areas.append(text)\n",
    "\n",
    "                    # Clean up the research areas using the custom function\n",
    "                    cleaned_areas = clean_research_areas(research_areas)\n",
    "\n",
    "                    # Create a dictionary for the faculty member's data\n",
    "                    faculty_data = {\n",
    "                        \"name\": faculty_name,\n",
    "                        \"research_areas\": cleaned_areas\n",
    "                    }\n",
    "\n",
    "                    # Append the dictionary to the list\n",
    "                    faculty_data_list.append(faculty_data)\n",
    "\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "# Now you have a list of dictionaries containing faculty data with cleaned research areas\n",
    "for faculty in faculty_data_list:\n",
    "    print(\"Faculty Name:\", faculty[\"name\"])\n",
    "    print(\"Research Areas:\", faculty[\"research_areas\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85cdbe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to faculty_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Define a custom function to clean up research areas\n",
    "def clean_research_areas(areas):\n",
    "    cleaned_areas = []\n",
    "    for area in areas:\n",
    "        # Remove extra whitespace, newlines, and empty lines\n",
    "        cleaned_area = \" \".join(area.split())\n",
    "        if cleaned_area:\n",
    "            cleaned_areas.append(cleaned_area)\n",
    "    return cleaned_areas\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Initialize an empty list to store faculty data\n",
    "faculty_data_list = []\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    research_areas = []\n",
    "\n",
    "                    # Extract the research areas\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        # Stop when another heading or paragraph is encountered\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        text = sibling.get_text()\n",
    "                        research_areas.append(text)\n",
    "\n",
    "                    # Clean up the research areas using the custom function\n",
    "                    cleaned_areas = clean_research_areas(research_areas)\n",
    "\n",
    "                    # Create a dictionary for the faculty member's data\n",
    "                    faculty_data = {\n",
    "                        \"name\": faculty_name,\n",
    "                        \"research_areas\": cleaned_areas\n",
    "                    }\n",
    "\n",
    "                    # Append the dictionary to the list\n",
    "                    faculty_data_list.append(faculty_data)\n",
    "\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "# Now you have a list of dictionaries containing faculty data with cleaned research areas\n",
    "\n",
    "# Create a Pandas DataFrame from the list of faculty data\n",
    "df = pd.DataFrame(faculty_data_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"faculty_data.csv\", index=False)\n",
    "\n",
    "print(\"Data saved to faculty_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4f21838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\USER\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory (directory where the script is located)\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c96778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Initialize an empty list to store faculty data\n",
    "faculty_data_list = []\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    # Extract the research areas\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        # Stop when another heading or paragraph is encountered\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        text = sibling.get_text().strip()\n",
    "                        if text:\n",
    "                            # Create a dictionary for each research area and faculty\n",
    "                            faculty_data = {\n",
    "                                \"name\": faculty_name,\n",
    "                                \"research_area\": text\n",
    "                            }\n",
    "                            faculty_data_list.append(faculty_data)\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "faculty_df = pd.DataFrame(faculty_data_list)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "faculty_df.to_csv(\"faculty_data_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de2cea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faculty Name: David (King Ip) Lin, Ph.D.\n",
      "Research Areas: ['Natural Language Processing', 'Database Systems', 'Data mining']\n",
      "\n",
      "Faculty Name: Theodore Manikas, Ph.D.\n",
      "Research Areas: ['Computer Architecture', 'Circuit Testing', 'Optimization Methods', 'Security']\n",
      "\n",
      "Faculty Name: Eric Larson, Ph.D.\n",
      "Research Areas: ['Machine Learning and Deep Learning', 'Privacy and Security', 'Applied Machine Learning in Health and Education', 'Human Machine Teaming and Biometrics']\n",
      "\n",
      "Faculty Name: Frank Coyle, Ph.D.\n",
      "Research Areas: ['Machine Learning / Artificial Intelligence', 'Software Engineering', 'Large Language Models']\n",
      "\n",
      "Faculty Name: Mehak Gupta, Ph.D.\n",
      "Research Areas: ['Deep Learning', 'Supervised and Semi-supervised machine learning', 'Structured and Unstructured medical data', 'Predictive modeling', 'Natural Language Processing']\n",
      "\n",
      "Faculty Name: Ginger Alford, Ph.D.\n",
      "Research Areas: ['Visual and Spatial Computing', 'Applications of Emerging Immersive 3D Technologies in Museums', 'Animatronics Education (Embedding robotics in arts and humanities stories)', 'Light Fields and Novel Displays', 'Applications of Blue Noise in Machine Learning']\n",
      "\n",
      "Faculty Name: Jia Zhang, Ph.D.\n",
      "Research Areas: ['Data Science Infrastructure', 'Machine Learning', 'Scientific Workflow', 'Software Engineering', 'Cloud Computing']\n",
      "\n",
      "Faculty Name: Jeff Tian, Ph.D.\n",
      "Research Areas: ['Software testing, especially usage-/risk-based testing', 'Usability and user experience (UX) measurement and improvement', 'Software measurement and empirical software engineering', 'Software reliability and safety', 'Cloud and service computing']\n",
      "\n",
      "Faculty Name: Kasilingam Periyasamy, Ph.D.\n",
      "Research Areas: ['Software Engineering', 'Formal Methods', 'Data Science', 'Healthcare Applications']\n",
      "\n",
      "Faculty Name: Klyne Smith, Eng.D.\n",
      "Research Areas: ['Software Engineering Life Cycle Model Delivery Engagement', 'Project Management Optimization and Risk Management', 'Intersection and Dependencies of Software Engineering and Project Management', 'Requirements and Software Engineering associated with Cybersecurity, Machine Learning, and Artificial Intelligence']\n",
      "\n",
      "Faculty Name: Labiba Jahan, Ph.D.\n",
      "Research Areas: ['Natural Language Processing', 'Narrative Understanding', 'Machine Learning']\n",
      "\n",
      "Faculty Name: LiGuo Huang, Ph.D.\n",
      "Research Areas: ['AI and Software Engineering', 'Software Data Analytics', 'Software Quality', 'Software Maintenance and Evolution', 'Software and System Processes', 'Empirical Software Engineering']\n",
      "\n",
      "Faculty Name: Maya El Dayeh, Ph.D.\n",
      "Research Areas: ['Cloud Computing', 'Data Mining', 'Software Engineering']\n",
      "\n",
      "Faculty Name: Michael Hahsler, Ph.D.\n",
      "Research Areas: ['Artificial Intelligence', 'Machine Learning', 'Data Mining', 'Data Science']\n",
      "\n",
      "Faculty Name: Nurcan Yuruk, Ph.D.\n",
      "Research Areas: ['Data Mining', 'Social Network Analysis', 'Applied Machine Learning']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Initialize an empty list to store faculty data\n",
    "faculty_data_list = []\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    # Extract the research areas as a list\n",
    "                    research_areas = []\n",
    "\n",
    "                    # Iterate through siblings and handle newlines as separate research areas\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        text = sibling.get_text().strip()\n",
    "                        if text:\n",
    "                            # Split text on newlines to separate research areas\n",
    "                            areas = re.split(r'\\n', text)\n",
    "                            research_areas.extend([area.strip() for area in areas if area.strip()])\n",
    "\n",
    "                    # Create a dictionary for the faculty member's data\n",
    "                    faculty_data = {\n",
    "                        \"name\": faculty_name,\n",
    "                        \"research_areas\": research_areas\n",
    "                    }\n",
    "\n",
    "                    # Append the dictionary to the list\n",
    "                    faculty_data_list.append(faculty_data)\n",
    "\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "# Now you have a list of dictionaries containing faculty data\n",
    "for faculty in faculty_data_list:\n",
    "    print(\"Faculty Name:\", faculty[\"name\"])\n",
    "    print(\"Research Areas:\", faculty[\"research_areas\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120826f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Initialize an empty list to store faculty data\n",
    "faculty_data_list = []\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    # Extract the research areas as a list\n",
    "                    research_areas = []\n",
    "\n",
    "                    # Iterate through siblings and handle newlines as separate research areas\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        text = sibling.get_text().strip()\n",
    "                        if text:\n",
    "                            # Split text on newlines to separate research areas\n",
    "                            areas = re.split(r'\\n', text)\n",
    "                            research_areas.extend([area.strip() for area in areas if area.strip()])\n",
    "\n",
    "                    # Create a dictionary for the faculty member's data\n",
    "                    faculty_data = {\n",
    "                        \"name\": faculty_name,\n",
    "                        \"research_areas\": \", \".join(research_areas)  # Join research areas with a comma\n",
    "                    }\n",
    "\n",
    "                    # Append the dictionary to the list\n",
    "                    faculty_data_list.append(faculty_data)\n",
    "\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "# Create a DataFrame from the list of faculty data\n",
    "faculty_df = pd.DataFrame(faculty_data_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "faculty_df.to_csv(\"faculty_data_latest.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d7a8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/CS/People/Faculty/\"\n",
    "\n",
    "# Initialize an empty list to store faculty data\n",
    "faculty_data_list = []\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    # Extract the research areas as a list\n",
    "                    research_areas = []\n",
    "\n",
    "                    # Iterate through siblings and handle newlines as separate research areas\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        text = sibling.get_text().strip()\n",
    "                        if text:\n",
    "                            # Split text on newlines to separate research areas\n",
    "                            areas = re.split(r'\\n', text)\n",
    "                            research_areas.extend([area.strip() for area in areas if area.strip()])\n",
    "\n",
    "                    # Create a dictionary for the faculty member's data\n",
    "                    for area in research_areas:\n",
    "                        faculty_data = {\n",
    "                            \"name\": faculty_name,\n",
    "                            \"research_area\": area\n",
    "                        }\n",
    "\n",
    "                        # Append the dictionary to the list\n",
    "                        faculty_data_list.append(faculty_data)\n",
    "\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "# Create a DataFrame from the list of faculty data\n",
    "faculty_df = pd.DataFrame(faculty_data_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "faculty_df.to_csv(\"faculty.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1342850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Research' not found on https://www.smu.edu/Lyle/Departments/ME/People/Faculty/Elena-Borzova.\n",
      "'Research' not found on https://www.smu.edu/Lyle/Departments/ME/People/Faculty/Jim-Webb.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "# URL of the page containing faculty names and links\n",
    "CS_url = \"https://www.smu.edu/Lyle/Departments/ME/People/Faculty\"\n",
    "\n",
    "# Initialize an empty list to store faculty data\n",
    "faculty_data_list = []\n",
    "\n",
    "# Unique ID counter\n",
    "id_counter = 1\n",
    "\n",
    "# Send an HTTP GET request to the base page\n",
    "response = requests.get(CS_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the base page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all faculty items (assuming they are within <li> tags)\n",
    "    faculty_items = soup.find_all(\"li\", class_=\"list-group-item subnavigation-item\")\n",
    "\n",
    "    # Iterate through faculty items\n",
    "    for faculty_item in faculty_items:\n",
    "        faculty_link = faculty_item.find(\"a\")[\"href\"] if faculty_item.find(\"a\") else None\n",
    "\n",
    "        if faculty_link:\n",
    "            # Make the URL absolute by joining it with the base URL\n",
    "            absolute_url = urljoin(CS_url, faculty_link)\n",
    "\n",
    "            # Send an HTTP GET request to the individual faculty member's page\n",
    "            faculty_response = requests.get(absolute_url)\n",
    "\n",
    "            # Check if the request to the faculty member's page was successful\n",
    "            if faculty_response.status_code == 200:\n",
    "                # Parse the HTML content of the faculty member's page\n",
    "                faculty_soup = BeautifulSoup(faculty_response.content, \"html.parser\")\n",
    "\n",
    "                # Extract the faculty name\n",
    "                faculty_name = faculty_soup.find(\"h1\").get_text().strip()  # Assuming the name is in an h1 tag\n",
    "\n",
    "                # Search for the \"Research\" heading on the faculty member's page\n",
    "                research_heading = faculty_soup.find(\"h3\", text=\"Research\")\n",
    "\n",
    "                if research_heading:\n",
    "                    # Extract the research areas as a list\n",
    "                    research_areas = []\n",
    "\n",
    "                    # Iterate through siblings and handle newlines as separate research areas\n",
    "                    for sibling in research_heading.find_next_siblings():\n",
    "                        if sibling.name in [\"h1\", \"h2\", \"h3\", \"p1\", \"li\"]:\n",
    "                            break\n",
    "                        text = sibling.get_text().strip()\n",
    "                        if text:\n",
    "                            # Split text on newlines to separate research areas\n",
    "                            areas = re.split(r'\\n', text)\n",
    "                            research_areas.extend([area.strip() for area in areas if area.strip()])\n",
    "\n",
    "                    # Create a dictionary for the faculty member's data\n",
    "                    for area in research_areas:\n",
    "                        faculty_data = {\n",
    "                            \"id\": id_counter,\n",
    "                            \"name\": faculty_name,\n",
    "                            \"research_area\": area\n",
    "                        }\n",
    "\n",
    "                        # Append the dictionary to the list\n",
    "                        faculty_data_list.append(faculty_data)\n",
    "\n",
    "                        # Increment the unique ID counter\n",
    "                        id_counter += 1\n",
    "\n",
    "                else:\n",
    "                    print(f\"'Research' not found on {absolute_url}.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch faculty member's page: {absolute_url}\")\n",
    "        else:\n",
    "            print(\"Faculty link not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the base page.\")\n",
    "\n",
    "# Create a DataFrame from the list of faculty data\n",
    "faculty_df = pd.DataFrame(faculty_data_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# faculty_df.to_csv(\"faculty_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e38332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>research_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ali Beskok, Ph.D.</td>\n",
       "      <td>Micro- and nano-scale transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ali Beskok, Ph.D.</td>\n",
       "      <td>Multiphase flow heat and mass transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ali Beskok, Ph.D.</td>\n",
       "      <td>AC Electrokinetic transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ali Beskok, Ph.D.</td>\n",
       "      <td>Bio-Microfluidics and Lab on a Chip Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David A. Willis, Ph.D.</td>\n",
       "      <td>Heat transfer and phase change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>David A. Willis, Ph.D.</td>\n",
       "      <td>Laser ablation and micromachining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>David A. Willis, Ph.D.</td>\n",
       "      <td>Laser-induced forward transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>David A. Willis, Ph.D.</td>\n",
       "      <td>Short-pulse laser-assisted microfabrication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Edmond Richer, Ph.D.</td>\n",
       "      <td>Advanced haptic interfaces and virtual modelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Edmond Richer, Ph.D.</td>\n",
       "      <td>Bio-Instrumentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Edmond Richer, Ph.D.</td>\n",
       "      <td>Medical robotics and intelligent orthotic devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Edmond Richer, Ph.D.</td>\n",
       "      <td>Soft and wearable robotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Edmond Richer, Ph.D.</td>\n",
       "      <td>Design and control of high-performance actuators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>José L. Lage, Ph.D.</td>\n",
       "      <td>Design of Complex Heat Exchangers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>José L. Lage, Ph.D.</td>\n",
       "      <td>Thermodynamics Systems and Processes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>José L. Lage, Ph.D.</td>\n",
       "      <td>Alveolar Gas Exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>José L. Lage, Ph.D.</td>\n",
       "      <td>Transport in Porous Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>MinJun Kim, Ph.D.</td>\n",
       "      <td>Thermal Science and Fluid Mechanics; Dynamics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>MinJun Kim, Ph.D.</td>\n",
       "      <td>Microbiorobotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>MinJun Kim, Ph.D.</td>\n",
       "      <td>Soft robotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>MinJun Kim, Ph.D.</td>\n",
       "      <td>Single molecule biophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>MinJun Kim, Ph.D.</td>\n",
       "      <td>Single cell analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>MinJun Kim, Ph.D.</td>\n",
       "      <td>Micro/nanofluidics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Steven L. Lerner, Ph.D.</td>\n",
       "      <td>Thermal systems design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Steven L. Lerner, Ph.D.</td>\n",
       "      <td>Sustainability, efficiency and energy recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Steven L. Lerner, Ph.D.</td>\n",
       "      <td>Corporate innovation management practices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Steven L. Lerner, Ph.D.</td>\n",
       "      <td>Medical devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Volkan Otugen, Ph.D.</td>\n",
       "      <td>Experimental and theoretical fluid mechanics a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Volkan Otugen, Ph.D.</td>\n",
       "      <td>High-speed aerodynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Volkan Otugen, Ph.D.</td>\n",
       "      <td>Plasma applications to aerodynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Volkan Otugen, Ph.D.</td>\n",
       "      <td>Photonic sensors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Wei Tong, Ph.D.</td>\n",
       "      <td>Metal plasticity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Wei Tong, Ph.D.</td>\n",
       "      <td>Ductile failure and fracture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>Wei Tong, Ph.D.</td>\n",
       "      <td>Laser welding and additive manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Wei Tong, Ph.D.</td>\n",
       "      <td>Experimental solid mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Xin-Lin Gao, Ph.D.</td>\n",
       "      <td>Solid and structural mechanics (beams, plates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>Xin-Lin Gao, Ph.D.</td>\n",
       "      <td>Multiscale and multi-physics modeling of mater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>Xin-Lin Gao, Ph.D.</td>\n",
       "      <td>Higher-order continuum theories, micro- and na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Xin-Lin Gao, Ph.D.</td>\n",
       "      <td>Metamaterials, nanocomposites, cellular and la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>Xin-Lin Gao, Ph.D.</td>\n",
       "      <td>Traumatic brain injury, biomechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>Xin-Lin Gao, Ph.D.</td>\n",
       "      <td>Impact mechanics, wave Propagation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>Xin-Lin Gao, Ph.D.</td>\n",
       "      <td>Topology optimization, inverse design based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>Xin-Lin Gao, Ph.D.</td>\n",
       "      <td>Additive manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>Xu Nie, Ph.D.</td>\n",
       "      <td>Dynamic behavior of advanced materials and str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>Xu Nie, Ph.D.</td>\n",
       "      <td>High-rate experimental mechanics and techniques.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>Xu Nie, Ph.D.</td>\n",
       "      <td>Microstructure and damage evolution in enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>Xu Nie, Ph.D.</td>\n",
       "      <td>Characterization and modeling of metal plastic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>Xu Nie, Ph.D.</td>\n",
       "      <td>Damage diagnosis using X-ray micro tomography.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>Yildirim Hurmuzlu, Ph.D.</td>\n",
       "      <td>Hurmuzlu, Y., (2020). Complementarity Relation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>Yildirim Hurmuzlu, Ph.D.</td>\n",
       "      <td>ASME Journal of Applied Mechanics, 87(12).</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                      name  \\\n",
       "0    1         Ali Beskok, Ph.D.   \n",
       "1    2         Ali Beskok, Ph.D.   \n",
       "2    3         Ali Beskok, Ph.D.   \n",
       "3    4         Ali Beskok, Ph.D.   \n",
       "4    5    David A. Willis, Ph.D.   \n",
       "5    6    David A. Willis, Ph.D.   \n",
       "6    7    David A. Willis, Ph.D.   \n",
       "7    8    David A. Willis, Ph.D.   \n",
       "8    9      Edmond Richer, Ph.D.   \n",
       "9   10      Edmond Richer, Ph.D.   \n",
       "10  11      Edmond Richer, Ph.D.   \n",
       "11  12      Edmond Richer, Ph.D.   \n",
       "12  13      Edmond Richer, Ph.D.   \n",
       "13  14       José L. Lage, Ph.D.   \n",
       "14  15       José L. Lage, Ph.D.   \n",
       "15  16       José L. Lage, Ph.D.   \n",
       "16  17       José L. Lage, Ph.D.   \n",
       "17  18         MinJun Kim, Ph.D.   \n",
       "18  19         MinJun Kim, Ph.D.   \n",
       "19  20         MinJun Kim, Ph.D.   \n",
       "20  21         MinJun Kim, Ph.D.   \n",
       "21  22         MinJun Kim, Ph.D.   \n",
       "22  23         MinJun Kim, Ph.D.   \n",
       "23  24   Steven L. Lerner, Ph.D.   \n",
       "24  25   Steven L. Lerner, Ph.D.   \n",
       "25  26   Steven L. Lerner, Ph.D.   \n",
       "26  27   Steven L. Lerner, Ph.D.   \n",
       "27  28      Volkan Otugen, Ph.D.   \n",
       "28  29      Volkan Otugen, Ph.D.   \n",
       "29  30      Volkan Otugen, Ph.D.   \n",
       "30  31      Volkan Otugen, Ph.D.   \n",
       "31  32           Wei Tong, Ph.D.   \n",
       "32  33           Wei Tong, Ph.D.   \n",
       "33  34           Wei Tong, Ph.D.   \n",
       "34  35           Wei Tong, Ph.D.   \n",
       "35  36        Xin-Lin Gao, Ph.D.   \n",
       "36  37        Xin-Lin Gao, Ph.D.   \n",
       "37  38        Xin-Lin Gao, Ph.D.   \n",
       "38  39        Xin-Lin Gao, Ph.D.   \n",
       "39  40        Xin-Lin Gao, Ph.D.   \n",
       "40  41        Xin-Lin Gao, Ph.D.   \n",
       "41  42        Xin-Lin Gao, Ph.D.   \n",
       "42  43        Xin-Lin Gao, Ph.D.   \n",
       "43  44             Xu Nie, Ph.D.   \n",
       "44  45             Xu Nie, Ph.D.   \n",
       "45  46             Xu Nie, Ph.D.   \n",
       "46  47             Xu Nie, Ph.D.   \n",
       "47  48             Xu Nie, Ph.D.   \n",
       "48  49  Yildirim Hurmuzlu, Ph.D.   \n",
       "49  50  Yildirim Hurmuzlu, Ph.D.   \n",
       "\n",
       "                                        research_area  \n",
       "0                     Micro- and nano-scale transport  \n",
       "1              Multiphase flow heat and mass transfer  \n",
       "2                         AC Electrokinetic transport  \n",
       "3    Bio-Microfluidics and Lab on a Chip Technologies  \n",
       "4                      Heat transfer and phase change  \n",
       "5                   Laser ablation and micromachining  \n",
       "6                      Laser-induced forward transfer  \n",
       "7         Short-pulse laser-assisted microfabrication  \n",
       "8   Advanced haptic interfaces and virtual modelin...  \n",
       "9                                 Bio-Instrumentation  \n",
       "10  Medical robotics and intelligent orthotic devices  \n",
       "11                         Soft and wearable robotics  \n",
       "12   Design and control of high-performance actuators  \n",
       "13                  Design of Complex Heat Exchangers  \n",
       "14               Thermodynamics Systems and Processes  \n",
       "15                              Alveolar Gas Exchange  \n",
       "16                          Transport in Porous Media  \n",
       "17  Thermal Science and Fluid Mechanics; Dynamics ...  \n",
       "18                                   Microbiorobotics  \n",
       "19                                      Soft robotics  \n",
       "20                         Single molecule biophysics  \n",
       "21                               Single cell analysis  \n",
       "22                                 Micro/nanofluidics  \n",
       "23                             Thermal systems design  \n",
       "24     Sustainability, efficiency and energy recovery  \n",
       "25          Corporate innovation management practices  \n",
       "26                                    Medical devices  \n",
       "27  Experimental and theoretical fluid mechanics a...  \n",
       "28                            High-speed aerodynamics  \n",
       "29                Plasma applications to aerodynamics  \n",
       "30                                   Photonic sensors  \n",
       "31                                   Metal plasticity  \n",
       "32                       Ductile failure and fracture  \n",
       "33           Laser welding and additive manufacturing  \n",
       "34                       Experimental solid mechanics  \n",
       "35  Solid and structural mechanics (beams, plates ...  \n",
       "36  Multiscale and multi-physics modeling of mater...  \n",
       "37  Higher-order continuum theories, micro- and na...  \n",
       "38  Metamaterials, nanocomposites, cellular and la...  \n",
       "39               Traumatic brain injury, biomechanics  \n",
       "40                 Impact mechanics, wave Propagation  \n",
       "41  Topology optimization, inverse design based on...  \n",
       "42                             Additive manufacturing  \n",
       "43  Dynamic behavior of advanced materials and str...  \n",
       "44   High-rate experimental mechanics and techniques.  \n",
       "45  Microstructure and damage evolution in enginee...  \n",
       "46  Characterization and modeling of metal plastic...  \n",
       "47     Damage diagnosis using X-ray micro tomography.  \n",
       "48  Hurmuzlu, Y., (2020). Complementarity Relation...  \n",
       "49         ASME Journal of Applied Mechanics, 87(12).  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faculty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b27d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
